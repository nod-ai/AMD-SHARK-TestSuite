# Copyright 2025 Advanced Micro Devices
#
# Licensed under the Apache License v2.0 with LLVM Exceptions.
# See https://llvm.org/LICENSE.txt for license information.
# SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception

name: HF Top-1000 models Test Suite
on:
  workflow_dispatch:
  schedule:
  # Runs at 2:30 AM PST
  - cron: '0 1 * * 1-6'


jobs:
  e2eamdshark:
    timeout-minutes: 6000
    name: "Models :: ${{ matrix.backend }} :: ${{ matrix.test-file }}"
    runs-on: ${{ matrix.runs-on }}
    strategy:
      fail-fast: false
      matrix:
        include:
          - name: mi325_gpu1_test
            runs-on: linux-mi325-1gpu-ossci-nod-ai
            backend: rocm
            device: hip
            target-chip: gfx942
            test-file: hf-feature-extraction-shard
            cache-dir: /home/runner/data/e2eamdshark/amdshark-test-suite-models-cache
          - name: mi325_gpu2_test
            runs-on: linux-mi325-1gpu-ossci-nod-ai
            backend: rocm
            device: hip
            target-chip: gfx942
            test-file: hf-fill-mask-shard
            cache-dir: /home/runner/data/e2eamdshark/amdshark-test-suite-models-cache
          - name: mi325_gpu3_test
            runs-on: linux-mi325-1gpu-ossci-nod-ai
            backend: rocm
            device: hip
            target-chip: gfx942
            test-file: hf-image-classification-shard
            cache-dir: /home/runner/data/e2eamdshark/amdshark-test-suite-models-cache
          - name: mi325_gpu4_test
            runs-on: linux-mi325-1gpu-ossci-nod-ai
            backend: rocm
            device: hip
            target-chip: gfx942
            test-file: hf-image-segmentation-shard
            cache-dir: /home/runner/data/e2eamdshark/amdshark-test-suite-models-cache
          - name: mi325_gpu5_test
            runs-on: linux-mi325-1gpu-ossci-nod-ai
            backend: rocm
            device: hip
            target-chip: gfx942
            test-file: hf-multiple-choice-shard
            cache-dir: /home/runner/data/e2eamdshark/amdshark-test-suite-models-cache
          - name: mi325_gpu6_test
            runs-on: linux-mi325-1gpu-ossci-nod-ai
            backend: rocm
            device: hip
            target-chip: gfx942
            test-file: hf-object-detection-shard
            cache-dir: /home/runner/data/e2eamdshark/amdshark-test-suite-models-cache
          - name: mi325_gpu7_test
            runs-on: linux-mi325-1gpu-ossci-nod-ai
            backend: rocm
            device: hip
            target-chip: gfx942
            test-file: hf-question-answering-shard
            cache-dir: /home/runner/data/e2eamdshark/amdshark-test-suite-models-cache
          - name: mi325_gpu8_test
            runs-on: linux-mi325-1gpu-ossci-nod-ai
            backend: rocm
            device: hip
            target-chip: gfx942
            test-file: hf-semantic-segmentation-shard
            cache-dir: /home/runner/data/e2eamdshark/amdshark-test-suite-models-cache
          - name: mi325_gpu9_test
            runs-on: linux-mi325-1gpu-ossci-nod-ai
            backend: rocm
            device: hip
            target-chip: gfx942
            test-file: hf-text-classification-shard
            cache-dir: /home/runner/data/e2eamdshark/amdshark-test-suite-models-cache
          - name: mi325_gpu10_test
            runs-on: linux-mi325-1gpu-ossci-nod-ai
            backend: rocm
            device: hip
            target-chip: gfx942
            test-file: hf-text-generation-shard
            cache-dir: /home/runner/data/e2eamdshark/amdshark-test-suite-models-cache
          - name: mi325_gpu11_test
            runs-on: linux-mi325-1gpu-ossci-nod-ai
            backend: rocm
            device: hip
            target-chip: gfx942
            test-file: hf-token-classification-shard
            cache-dir: /home/runner/data/e2eamdshark/amdshark-test-suite-models-cache
          - name: cpu_shard1_test
            runs-on: nodai-cpu-x86-64
            backend: llvm-cpu
            device: local-task
            target-chip: x86_64-linux-gnu
            test-file: hf-feature-extraction-shard
            cache-dir: /home/runner/groups/aig_amdsharks/test-suite-ci-cache
          - name: cpu_shard2_test
            runs-on: nodai-cpu-x86-64
            backend: llvm-cpu
            device: local-task
            target-chip: x86_64-linux-gnu
            test-file: hf-fill-mask-shard
            cache-dir: /home/runner/groups/aig_amdsharks/test-suite-ci-cache
          - name: cpu_shard3_test
            runs-on: nodai-cpu-x86-64
            backend: llvm-cpu
            device: local-task
            target-chip: x86_64-linux-gnu
            test-file: hf-image-classification-shard
            cache-dir: /home/runner/groups/aig_amdsharks/test-suite-ci-cache
          - name: cpu_shard4_test
            runs-on: nodai-cpu-x86-64
            backend: llvm-cpu
            device: local-task
            target-chip: x86_64-linux-gnu
            test-file: hf-image-segmentation-shard
            cache-dir: /home/runner/groups/aig_amdsharks/test-suite-ci-cache
          - name: cpu_shard5_test
            runs-on: nodai-cpu-x86-64
            backend: llvm-cpu
            device: local-task
            target-chip: x86_64-linux-gnu
            test-file: hf-multiple-choice-shard
            cache-dir: /home/runner/groups/aig_amdsharks/test-suite-ci-cache
          - name: cpu_shard6_test
            runs-on: nodai-cpu-x86-64
            backend: llvm-cpu
            device: local-task
            target-chip: x86_64-linux-gnu
            test-file: hf-object-detection-shard
            cache-dir: /home/runner/groups/aig_amdsharks/test-suite-ci-cache
          - name: cpu_shard7_test
            runs-on: nodai-cpu-x86-64
            backend: llvm-cpu
            device: local-task
            target-chip: x86_64-linux-gnu
            test-file: hf-question-answering-shard
            cache-dir: /home/runner/groups/aig_amdsharks/test-suite-ci-cache
          - name: cpu_shard8_test
            runs-on: nodai-cpu-x86-64
            backend: llvm-cpu
            device: local-task
            target-chip: x86_64-linux-gnu
            test-file: hf-semantic-segmentation-shard
            cache-dir: /home/runner/groups/aig_amdsharks/test-suite-ci-cache
          - name: cpu_shard9_test
            runs-on: nodai-cpu-x86-64
            backend: llvm-cpu
            device: local-task
            target-chip: x86_64-linux-gnu
            test-file: hf-text-classification-shard
            cache-dir: /home/runner/groups/aig_amdsharks/test-suite-ci-cache
          #- name: cpu_shard10_test
          #  runs-on: nodai-cpu-x86-64
          #  backend: llvm-cpu
          #  device: local-task
          #  target-chip: x86_64-linux-gnu
          #  test-file: hf-text-generation-shard ## this is failing on CPU
          #  cache-dir: /home/runner/groups/aig_amdsharks/test-suite-ci-cache
          - name: cpu_shard11_test
            runs-on: nodai-cpu-x86-64
            backend: llvm-cpu
            device: local-task
            target-chip: x86_64-linux-gnu
            test-file: hf-token-classification-shard
            cache-dir: /home/runner/groups/aig_amdsharks/test-suite-ci-cache
    defaults:
      run:
        shell: bash
    env:
      E2E_VENV_DIR: ${{ github.workspace }}/test-suite_venv
      #EP_VENV_DIR: ${{ github.workspace }}/ep_venv
      ALT_E2E_VENV_DIR: ${{ github.workspace }}/alt-test-suite_venv
      HF_TOKEN: ${{ secrets.HF_TOKEN }}
      AZ_PRIVATE_CONNECTION: ${{ secrets.ONNXPRIVATESTORAGE_AZ_PRIVATE_CONNECTION }}
      CACHE_DIR: ${{ matrix.cache-dir }}
    steps:
      - name: "Setting up Python"
        id: setup_python
        uses: actions/setup-python@a26af69be951a213d495a4c3e4e4022e16d87065 # v5.6.0
        with:
          python-version: "3.11"

      - name: Checkout Test Suite
        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2
        with:
          repository: nod-ai/AMD-SHARK-TestSuite
          path: test-suite

      - name: "Setup alt e2eamdshark python venv"
        run: |
          rm -rf ${ALT_E2E_VENV_DIR}
          sudo apt update
          sudo apt install wget
          python -m venv ${ALT_E2E_VENV_DIR}
          source ${ALT_E2E_VENV_DIR}/bin/activate
          pip install --upgrade pip
          pip install -r ./alt_e2eamdshark/base_requirements.txt
          pip install -r ./alt_e2eamdshark/hf_requirements.txt
          pip install -r ./alt_e2eamdshark/iree_requirements.txt
          pip install --no-deps -r ./alt_e2eamdshark/torch_mlir_requirements.txt
          pip install --pre --upgrade iree-base-compiler iree-base-runtime -f https://iree.dev/pip-release-links.html
        working-directory: ./test-suite

      - name: Run HF top-1000 model
        run: |
          source ${ALT_E2E_VENV_DIR}/bin/activate
          pip freeze
          cd alt_e2eamdshark
          free -mh
          python3.11 ./run.py \
            -r ./test-onnx \
            --report \
            --testsfile onnx_tests/models/external_lists/hf-model-shards/${{ matrix.test-file }}.txt \
            -b ${{ matrix.backend }} \
            -d ${{ matrix.device }} \
            -c ${{ matrix.target-chip }} \
            --report-file reports/${{ matrix.test-file }}.md \
            --mode=cl-onnx-iree \
            --cleanup=3 \
            --get-metadata \
            -v
          python utils/find_duplicate_models.py -s -r ./test-onnx -o reports/duplicates.json
        working-directory: ./test-suite

      - uses: actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02 # v4.6.2
        with:
          name: ci_reports_${{ matrix.backend }}_${{ matrix.test-file }}_onnx_md
          path: ./test-suite/alt_e2eamdshark/reports/${{ matrix.test-file }}.md

      - uses: actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02 # v4.6.2
        with:
          name: ci_reports_${{ matrix.backend }}_${{ matrix.test-file }}_onnx_json
          path: ./test-suite/alt_e2eamdshark/reports/${{ matrix.test-file }}.json

      - uses: actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02 # v4.6.2
        with:
          name: ci_reports_${{ matrix.backend }}_${{ matrix.test-file }}_duplicates_json
          path: ./test-suite/alt_e2eamdshark/duplicates.json


  push_artifacts:
    needs: [e2eamdshark]
    runs-on: ${{ matrix.runs-on }}
    if: always()
    strategy:
      fail-fast: false
      max-parallel: 1
      matrix:
        include:
          - name: merge_rocm_reports
            runs-on: linux-mi325-1gpu-ossci-nod-ai
            backend: rocm
            regression-blob: rocm
            device: hip
            target-chip: gfx942
            cache-dir: /home/runner/data/e2eamdshark/amdshark-test-suite-models-cache
          - name: merge_cpu_reports
            runs-on: nodai-cpu-x86-64
            backend: llvm-cpu
            regression-blob: cpu
            device: local-task
            target-chip: x86_64-linux-gnu
            cache-dir: /home/runner/groups/aig_amdsharks/test-suite-ci-cache
    env:
      AZ_PUBLIC_KEY: ${{ secrets.AMD_SHARKPUBLIC_AZ_KEY }}
      CACHE_DIR: ${{ matrix.cache-dir }}
    steps:
      - name: Checkout Test Suite
        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2
        with:
          repository: nod-ai/AMD-SHARK-TestSuite
          path: test-suite
      - name: Checkout repo
        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2
        with:
          repository: nod-ai/e2eamdshark-reports
          ref: main
          token: ${{ secrets.E2EAMDSHARK_GITHUB_TOKEN }}
          path: e2eamdshark-reports
      - name: "Setting up Python"
        id: setup_python
        uses: actions/setup-python@a26af69be951a213d495a4c3e4e4022e16d87065 # v5.6.0
        with:
          python-version: "3.11"
      - name: "Setup alt test suite venv"
        run: |
          sudo apt update
          sudo apt install wget
          curl -sL https://aka.ms/InstallAzureCLIDeb | sudo bash
          python -m venv report_venv_alt
          source report_venv_alt/bin/activate
          pip install --upgrade pip
          pip install -r ./test-suite/alt_e2eamdshark/base_requirements.txt
          pip install -r ./test-suite/alt_e2eamdshark/hf_requirements.txt
          pip install -r ./test-suite/alt_e2eamdshark/iree_requirements.txt
          pip install --no-deps -r ./test-suite/alt_e2eamdshark/torch_mlir_requirements.txt
          pip install --pre --upgrade iree-base-compiler iree-base-runtime -f https://iree.dev/pip-release-links.html

      - uses: actions/download-artifact@95815c38cf2ff2164869cbab79da8d1f422bc89e # v4.2.1
        with:
          name: ci_reports_${{ matrix.backend }}_hf-feature-extraction-shard_onnx_md
          path: ./e2eamdshark-reports/ci_reports_${{ matrix.backend }}_hf-feature-extraction-shard_onnx_md
      - uses: actions/download-artifact@95815c38cf2ff2164869cbab79da8d1f422bc89e # v4.2.1
        with:
          name: ci_reports_${{ matrix.backend }}_hf-feature-extraction-shard_onnx_json
          path: ./e2eamdshark-reports/ci_reports_${{ matrix.backend }}_hf-feature-extraction-shard_onnx_json
      - uses: actions/download-artifact@95815c38cf2ff2164869cbab79da8d1f422bc89e # v4.2.1
        with:
          name: ci_reports_${{ matrix.backend }}_hf-fill-mask-shard_onnx_md
          path: ./e2eamdshark-reports/ci_reports_${{ matrix.backend }}_hf-fill-mask-shard_onnx_md
      - uses: actions/download-artifact@95815c38cf2ff2164869cbab79da8d1f422bc89e # v4.2.1
        with:
          name: ci_reports_${{ matrix.backend }}_hf-fill-mask-shard_onnx_json
          path: ./e2eamdshark-reports/ci_reports_${{ matrix.backend }}_hf-fill-mask-shard_onnx_json
      - uses: actions/download-artifact@master
        with:
          name: ci_reports_${{ matrix.backend }}_hf-image-classification-shard_onnx_md
          path: ./e2eamdshark-reports/ci_reports_${{ matrix.backend }}_hf-image-classification-shard_onnx_md
      - uses: actions/download-artifact@master
        with:
          name: ci_reports_${{ matrix.backend }}_hf-image-classification-shard_onnx_json
          path: ./e2eamdshark-reports/ci_reports_${{ matrix.backend }}_hf-image-classification-shard_onnx_json
      - uses: actions/download-artifact@master
        with:
          name: ci_reports_${{ matrix.backend }}_hf-image-segmentation-shard_onnx_md
          path: ./e2eamdshark-reports/ci_reports_${{ matrix.backend }}_hf-image-segmentation-shard_onnx_md
      - uses: actions/download-artifact@master
        with:
          name: ci_reports_${{ matrix.backend }}_hf-image-segmentation-shard_onnx_json
          path: ./e2eamdshark-reports/ci_reports_${{ matrix.backend }}_hf-image-segmentation-shard_onnx_json
      - uses: actions/download-artifact@master
        with:
          name: ci_reports_${{ matrix.backend }}_hf-multiple-choice-shard_onnx_md
          path: ./e2eamdshark-reports/ci_reports_${{ matrix.backend }}_hf-multiple-choice-shard_onnx_md
      - uses: actions/download-artifact@master
        with:
          name: ci_reports_${{ matrix.backend }}_hf-multiple-choice-shard_onnx_json
          path: ./e2eamdshark-reports/ci_reports_${{ matrix.backend }}_hf-multiple-choice-shard_onnx_json
      - uses: actions/download-artifact@master
        with:
          name: ci_reports_${{ matrix.backend }}_hf-object-detection-shard_onnx_md
          path: ./e2eamdshark-reports/ci_reports_${{ matrix.backend }}_hf-object-detection-shard_onnx_md
      - uses: actions/download-artifact@master
        with:
          name: ci_reports_${{ matrix.backend }}_hf-object-detection-shard_onnx_json
          path: ./e2eamdshark-reports/ci_reports_${{ matrix.backend }}_hf-object-detection-shard_onnx_json
      - uses: actions/download-artifact@master
        with:
          name: ci_reports_${{ matrix.backend }}_hf-question-answering-shard_onnx_md
          path: ./e2eamdshark-reports/ci_reports_${{ matrix.backend }}_hf-question-answering-shard_onnx_md
      - uses: actions/download-artifact@master
        with:
          name: ci_reports_${{ matrix.backend }}_hf-question-answering-shard_onnx_json
          path: ./e2eamdshark-reports/ci_reports_${{ matrix.backend }}_hf-question-answering-shard_onnx_json
      - uses: actions/download-artifact@master
        with:
          name: ci_reports_${{ matrix.backend }}_hf-semantic-segmentation-shard_onnx_md
          path: ./e2eamdshark-reports/ci_reports_${{ matrix.backend }}_hf-semantic-segmentation-shard_onnx_md
      - uses: actions/download-artifact@master
        with:
          name: ci_reports_${{ matrix.backend }}_hf-semantic-segmentation-shard_onnx_json
          path: ./e2eamdshark-reports/ci_reports_${{ matrix.backend }}_hf-semantic-segmentation-shard_onnx_json
      - uses: actions/download-artifact@master
        with:
          name: ci_reports_${{ matrix.backend }}_hf-text-classification-shard_onnx_md
          path: ./e2eamdshark-reports/ci_reports_${{ matrix.backend }}_hf-text-classification-shard_onnx_md
      - uses: actions/download-artifact@master
        with:
          name: ci_reports_${{ matrix.backend }}_hf-text-classification-shard_onnx_json
          path: ./e2eamdshark-reports/ci_reports_${{ matrix.backend }}_hf-text-classification-shard_onnx_json
      #- uses: actions/download-artifact@master
      #  with:
      #    name: ci_reports_${{ matrix.backend }}_hf-text-generation-shard_onnx_md
      #    path: ./e2eamdshark-reports/ci_reports_${{ matrix.backend }}_hf-text-generation-shard_onnx_md
      #- uses: actions/download-artifact@master
      #  with:
      #    name: ci_reports_${{ matrix.backend }}_hf-text-generation-shard_onnx_json
      #    path: ./e2eamdshark-reports/ci_reports_${{ matrix.backend }}_hf-text-generation-shard_onnx_json
      - uses: actions/download-artifact@master
        with:
          name: ci_reports_${{ matrix.backend }}_hf-token-classification-shard_onnx_md
          path: ./e2eamdshark-reports/ci_reports_${{ matrix.backend }}_hf-token-classification-shard_onnx_md
      - uses: actions/download-artifact@master
        with:
          name: ci_reports_${{ matrix.backend }}_hf-token-classification-shard_onnx_json
          path: ./e2eamdshark-reports/ci_reports_${{ matrix.backend }}_hf-token-classification-shard_onnx_json

      - name: Merge Reports
        run: |
          source report_venv_alt/bin/activate
          python ./test-suite/alt_e2eamdshark/utils/merge_dicts.py \
            --sources ./e2eamdshark-reports/ci_reports_${{ matrix.backend }}_hf-feature-extraction-shard_onnx_json/hf-feature-extraction-shard.json \
            ./e2eamdshark-reports/ci_reports_${{ matrix.backend }}_hf-fill-mask-shard_onnx_json/hf-fill-mask-shard.json \
            ./e2eamdshark-reports/ci_reports_${{ matrix.backend }}_hf-image-classification-shard_onnx_json/hf-image-classification-shard.json \
            ./e2eamdshark-reports/ci_reports_${{ matrix.backend }}_hf-image-segmentation-shard_onnx_json/hf-image-segmentation-shard.json \
            ./e2eamdshark-reports/ci_reports_${{ matrix.backend }}_hf-multiple-choice-shard_onnx_json/hf-multiple-choice-shard.json \
            ./e2eamdshark-reports/ci_reports_${{ matrix.backend }}_hf-object-detection-shard_onnx_json/hf-object-detection-shard.json \
            ./e2eamdshark-reports/ci_reports_${{ matrix.backend }}_hf-question-answering-shard_onnx_json/hf-question-answering-shard.json \
            ./e2eamdshark-reports/ci_reports_${{ matrix.backend }}_hf-semantic-segmentation-shard_onnx_json/hf-semantic-segmentation-shard.json \
            ./e2eamdshark-reports/ci_reports_${{ matrix.backend }}_hf-text-classification-shard_onnx_json/hf-text-classification-shard.json \
            ./e2eamdshark-reports/ci_reports_${{ matrix.backend }}_hf-token-classification-shard_onnx_json/hf-token-classification-shard.json \
            --output ./e2eamdshark-reports/combined_reports_unique.json \
            --report --report-file ./e2eamdshark-reports/combined_reports_unique.md

      - name: Push status artifacts
        run: |
          git config user.name "GitHub Actions Bot"
          git config user.email "<>"
          git pull
          date=$(date '+%Y-%m-%d')
          mkdir -p ${date}/hf-model-top1k/${{ matrix.backend }}/hf-feature-extraction-shard
          mkdir -p ${date}/hf-model-top1k/${{ matrix.backend }}/hf-fill-mask-shard
          mkdir -p ${date}/hf-model-top1k/${{ matrix.backend }}/hf-image-classification-shard
          mkdir -p ${date}/hf-model-top1k/${{ matrix.backend }}/hf-image-segmentation-shard
          mkdir -p ${date}/hf-model-top1k/${{ matrix.backend }}/hf-multiple-choice-shard
          mkdir -p ${date}/hf-model-top1k/${{ matrix.backend }}/hf-object-detection-shard
          mkdir -p ${date}/hf-model-top1k/${{ matrix.backend }}/hf-question-answering-shard
          mkdir -p ${date}/hf-model-top1k/${{ matrix.backend }}/hf-semantic-segmentation-shard
          mkdir -p ${date}/hf-model-top1k/${{ matrix.backend }}/hf-text-classification-shard
          mkdir -p ${date}/hf-model-top1k/${{ matrix.backend }}/hf-token-classification-shard
          mkdir -p ${date}/hf-model-top1k/${{ matrix.backend }}/combined-reports_unique
          cp ci_reports_${{ matrix.backend }}_hf-feature-extraction-shard_onnx_md/hf-feature-extraction-shard.md ${date}/hf-model-top1k/${{ matrix.backend }}/hf-feature-extraction-shard/summary.md
          cp ci_reports_${{ matrix.backend }}_hf-fill-mask-shard_onnx_md/hf-fill-mask-shard.md ${date}/hf-model-top1k/${{ matrix.backend }}/hf-fill-mask-shard/summary.md
          cp ci_reports_${{ matrix.backend }}_hf-image-classification-shard_onnx_md/hf-image-classification-shard.md ${date}/hf-model-top1k/${{ matrix.backend }}/hf-image-classification-shard/summary.md
          cp ci_reports_${{ matrix.backend }}_hf-image-segmentation-shard_onnx_md/hf-image-segmentation-shard.md ${date}/hf-model-top1k/${{ matrix.backend }}/hf-image-segmentation-shard/summary.md
          cp ci_reports_${{ matrix.backend }}_hf-multiple-choice-shard_onnx_md/hf-multiple-choice-shard.md ${date}/hf-model-top1k/${{ matrix.backend }}/hf-multiple-choice-shard/summary.md
          cp ci_reports_${{ matrix.backend }}_hf-object-detection-shard_onnx_md/hf-object-detection-shard.md ${date}/hf-model-top1k/${{ matrix.backend }}/hf-object-detection-shard/summary.md
          cp ci_reports_${{ matrix.backend }}_hf-question-answering-shard_onnx_md/hf-question-answering-shard.md ${date}/hf-model-top1k/${{ matrix.backend }}/hf-question-answering-shard/summary.md
          cp ci_reports_${{ matrix.backend }}_hf-semantic-segmentation-shard_onnx_md/hf-semantic-segmentation-shard.md ${date}/hf-model-top1k/${{ matrix.backend }}/hf-semantic-segmentation-shard/summary.md
          cp ci_reports_${{ matrix.backend }}_hf-text-classification-shard_onnx_md/hf-text-classification-shard.md ${date}/hf-model-top1k/${{ matrix.backend }}/hf-text-classification-shard/summary.md
          cp ci_reports_${{ matrix.backend }}_hf-token-classification-shard_onnx_md/hf-token-classification-shard.md ${date}/hf-model-top1k/${{ matrix.backend }}/hf-token-classification-shard/summary.md
          cp combined_reports_unique.md ${date}/hf-model-top1k/${{ matrix.backend }}/combined-reports_unique/summary.md
          git add $date
          git commit -m "add CI status reports for e2eamdshark for ${{ matrix.backend }}"
          git push origin main
        working-directory: ./e2eamdshark-reports

      - name: Regression Reports
        run: |
          source report_venv_alt/bin/activate
          cd test-suite
          mkdir latest
          mkdir baseline
          wget https://amdsharkpublic.blob.core.windows.net/ciartifacts/latest-test-suite/combined_reports_hf_top_1k_${{ matrix.backend }}.json -O latest/combined_reports_hf_top_1k_${{ matrix.backend }}.json
          wget https://amdsharkpublic.blob.core.windows.net/ciartifacts/baseline-test-suite/combined_reports_hf_top_1k_${{ matrix.regression-blob }}.json -O baseline/combined_reports_hf_top_1k_${{ matrix.backend }}.json
          cd ..

          python ./test-suite/alt_e2eamdshark/utils/check_regressions.py \
            --new ./e2eamdshark-reports/combined_reports_unique.json \
            --old ./test-suite/latest/combined_reports_hf_top_1k_${{ matrix.backend }}.json \
            --report-file ./e2eamdshark-reports/yesterday_comparison.md \
            --perf_tol_regression=0.05 \
            --perf_tol_progression=0.05

          cat "e2eamdshark-reports/yesterday_comparison.md" || echo "[WARN] yesterday_comparison.md 1 not found or unreadable"

          # --- Recheck for Regression Models ---
          echo "================ starting recheck for regression models ================"
          # generate a json with model name and old status
          MD_FILE="e2eamdshark-reports/yesterday_comparison.md"
          python ./test-suite/alt_e2eamdshark/utils/extract_model_old_new_status_from_md.py "$MD_FILE" || echo "[WARN] Failed to extract model old/new status"
          cat "model_old_new_status.json" || echo "[WARN] model_old_new_status.json not generated"

          JSON_FILE="model_old_new_status.json"
          python ./test-suite/alt_e2eamdshark/utils/extract_regression_model_names.py "$JSON_FILE" || echo "[WARN] Failed to extract regression models from json"
          cat "regression_models.txt" || echo "[WARN] regression_models.txt not generated"

          cd test-suite/alt_e2eamdshark/ || echo "failed to cd into test-suite/alt_e2eamdshark/"
          REGRESSION_MODELS="$PWD/../../regression_models.txt"
          python ./run.py \
             -r ./test-onnx \
             --report \
             --testsfile $REGRESSION_MODELS \
             -b ${{ matrix.backend }} \
             -d ${{ matrix.device }} \
             -c ${{ matrix.target-chip }} \
             --report-file current_result.md \
             --mode=cl-onnx-iree \
             --cleanup=3 \
             --get-metadata \
             -v || echo "[WARN] run.py Regression test execution failed"
          cd ../..

          REGRESSION_MODELS="regression_models.txt"
          BASELINE_JSON="model_old_new_status.json"
          CURRENT_JSON="test-suite/alt_e2eamdshark/current_result.json"
          REPORT_MD="e2eamdshark-reports/yesterday_comparison.md"

          if [[ ! -f "$REGRESSION_MODELS" ]]; then
            echo "[WARN] regression_models.txt missing â€” skipping per-model updates"
          else
            while IFS= read -r MODEL; do
              # skip empty lines
              [[ -z "$MODEL" ]] && continue

              echo "Processing model: $MODEL"

              python test-suite/alt_e2eamdshark/utils/check_model_status_and_remove.py \
                "$MODEL" \
                "$BASELINE_JSON" \
                "$CURRENT_JSON" \
                "$REPORT_MD" || echo "[WARN] Failed to process model: $MODEL in check_model_status_and_remove.py"

            done < "$REGRESSION_MODELS"
          fi

          cat "e2eamdshark-reports/yesterday_comparison.md" || echo "[WARN] yesterday_comparison.md 2 not found or unreadable"

          echo "================ done recheck for regression models ================"

          # python ./test-suite/alt_e2eamdshark/utils/check_regressions.py \
          #   --new ./e2eamdshark-reports/combined_reports_unique.json \
          #   --old ./test-suite/baseline/combined_reports_hf_top_1k_${{ matrix.backend }}.json \
          #   --report-file ./e2eamdshark-reports/baseline_comparison.md \
          #   --perf_tol_regression=0.1 \
          #   --perf_tol_progression=0.1

          # az storage blob upload --account-name amdsharkpublic --container-name ciartifacts \
          #   --name latest-test-suite/combined_reports_hf_top_1k_${{ matrix.backend }}.json \
          #   --file ./e2eamdshark-reports/combined_reports_unique.json \
          #   --account-key ${AZ_PUBLIC_KEY} --overwrite

      # - name: Push regression artifacts
      #   run: |
      #     git config user.name "GitHub Actions Bot"
      #     git config user.email "<>"
      #     git pull
      #     date=$(date '+%Y-%m-%d')
      #     cp yesterday_comparison.md ${date}/hf-model-top1k/${{ matrix.backend }}/combined-reports_unique/yesterday_comparison.md
      #     cp baseline_comparison.md ${date}/hf-model-top1k/${{ matrix.backend }}/combined-reports_unique/baseline_comparison.md
      #     git add $date
      #     git commit -m "add CI regression reports for e2eamdshark for ${{ matrix.backend }}"
      #     git push origin main
      #   working-directory: ./e2eamdshark-reports
